{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../DATASET/digit-recognizer/train.csv')\n",
    "val_data = pd.read_csv('../DATASET/digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('label', axis=1)\n",
    "y = train_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Train Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_image(data, index):\n",
    "    image = data.iloc[index].values\n",
    "    image = image.reshape((28,28))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(data.iloc[index,0])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAKCElEQVR4nO3cT4hV5R/H8efkQErZokXkgLSZEaEhcqAumHvBpCAKCTfRQARtgwgzglmJILhUDBFcKLTVjRAEkRikbQLThUI0A4L0D2wmsNOmPhD2+3Wf49w5N+/rtTxzv5wvgvftg8zTtG3bFgAopTzU9wIAjA9RACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIESBiba6ulree++9Mj09XTZt2lQGg0G5cOFC32tBb0SBifbGG2+UI0eOlP3795ejR4+WDRs2lD179pTPP/+879WgF40L8ZhUX375ZRkMBuXw4cPl3XffLaWUsrKyUubm5soTTzxRvvjii543hPXnpMDE+uSTT8qGDRvKW2+9lWcbN24sCwsL5eLFi+W7777rcTvohygwsa5cuVK2bdtWHnvssb89f/7550sppXz99dc9bAX9EgUm1vLyctmyZcs9z/96trS0tN4rQe9EgYn166+/locffvie5xs3bszPYdKIAhNr06ZNZXV19Z7nKysr+TlMGlFgYm3ZsqUsLy/f8/yvZ9PT0+u9EvROFJhYzz77bLl27Vr5+eef//b80qVL+TlMGlFgYr366qvl7t275fjx43m2urpaTp48WQaDQdm6dWuP20E/pvpeAPoyGAzKa6+9Vt5///1y69atMjMzU06dOlVu3rxZPv74477Xg174jWYm2srKSjl48GA5ffp0+eGHH8ozzzxTFhcXy+7du/teDXohCgCE/1MAIEQBgBAFAEIUAAhRACBEAYAY+pfXmqYZ5R4AjNgwv4HgpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCADHV9wLwb7Zv3149880331TPnDlzpnrmnXfeqZ758ccfq2dgvTgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAETTtm071AebZtS78ICbnp7uNPfpp59Wz8zMzHR6V60uF+IdO3ZsBJvAvxvm695JAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYCY6nsBJscHH3zQaW52drZ6ZsjLf+/bnj17qmfm5uY6vWt+fr565uzZs9UzJ06cqJ65c+dO9QzjyUkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIFyIRycffvhh9czCwsIINunXiy++WD3TNE2nd3W55G8wGFTPPP7449UzH330UfUM48lJAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBciPeA2bp1a/XMoUOHqmf27dtXPdPVQw/V/9vl999/r565detW9cxvv/1WPTM11e2v3ZNPPtlprtajjz66Lu9hPDkpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQL8cbU9PR0p7kLFy5Uz8zMzFTPtG1bPdPVjRs3qme++uqr6pm33367eub27dvVM10uLSyl259DF/Pz8+vyHsaTkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4ZbUMbVv375Oc7Ozs9Uz63Xj6eLiYqe548ePV88sLy93ehfdbpjlweGkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAuxBtTly9fXre5paWl6pnz589Xz5w4caJ6ppRS7t6922kOqOekAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAuxBtTn332Wae55557bo03Ya0dPHiw01zTNGu8Sb/vYTw5KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEC/HgPuzdu7d6ZmFhodO72rbtNFdreXl5Xd7DeHJSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAgX4sF9mJ2d7XuFNXf27Nm+V6BHTgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhFtS4T7Mz8/3vcL/de3ateqZX375ZQSb8F/hpABAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQLsSDP+3atat65qWXXqqeaZqmeqarN998s3rmp59+GsEm/Fc4KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEC/HgT4cOHaqeeeSRR6pn2ratnimllG+//bZ65vr1653exeRyUgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIF+LxQJqbm6ueefrpp0ewyb3u3LnTae7AgQPVM7dv3+70LiaXkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBANG3btkN9sGlGvQv8o82bN1fPnDt3rnpm586d1TNdfP/9953mnnrqqTXehEkzzNe9kwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAMdX3AvBvXn755eqZF154YQSbrI1XXnml7xXgf3JSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIimbdt2qA82zah3gX909erV6pmZmZkRbHKvc+fOVc90ueAP1sIwX/dOCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAx1fcCTI7XX3+909zs7Gz1zJD3PN63xcXFdXkPrBcnBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYBwIR7rZmlpqdPc5cuXq2d27NhRPdPlcrsrV65Uz8A4c1IAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIJq2bduhPtg0o94FgBEa5uveSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAmBr2g23bjnIPAMaAkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDxB0ZnT74g4kExAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Example\n",
    "view_image(X_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### randomforest with tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n",
      "[CV 1/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 1/10; 1/40] END max_depth=1, n_estimators=10;, score=0.452 total time=   0.3s\n",
      "[CV 2/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 2/10; 1/40] END max_depth=1, n_estimators=10;, score=0.439 total time=   0.1s\n",
      "[CV 3/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 3/10; 1/40] END max_depth=1, n_estimators=10;, score=0.459 total time=   0.1s\n",
      "[CV 4/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 4/10; 1/40] END max_depth=1, n_estimators=10;, score=0.448 total time=   0.1s\n",
      "[CV 5/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 5/10; 1/40] END max_depth=1, n_estimators=10;, score=0.475 total time=   0.1s\n",
      "[CV 6/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 6/10; 1/40] END max_depth=1, n_estimators=10;, score=0.437 total time=   0.1s\n",
      "[CV 7/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 7/10; 1/40] END max_depth=1, n_estimators=10;, score=0.427 total time=   0.1s\n",
      "[CV 8/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 8/10; 1/40] END max_depth=1, n_estimators=10;, score=0.427 total time=   0.1s\n",
      "[CV 9/10; 1/40] START max_depth=1, n_estimators=10..............................\n",
      "[CV 9/10; 1/40] END max_depth=1, n_estimators=10;, score=0.429 total time=   0.1s\n",
      "[CV 10/10; 1/40] START max_depth=1, n_estimators=10.............................\n",
      "[CV 10/10; 1/40] END max_depth=1, n_estimators=10;, score=0.429 total time=   0.1s\n",
      "[CV 1/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 1/10; 2/40] END max_depth=1, n_estimators=20;, score=0.499 total time=   0.2s\n",
      "[CV 2/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 2/10; 2/40] END max_depth=1, n_estimators=20;, score=0.474 total time=   0.2s\n",
      "[CV 3/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 3/10; 2/40] END max_depth=1, n_estimators=20;, score=0.483 total time=   0.2s\n",
      "[CV 4/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 4/10; 2/40] END max_depth=1, n_estimators=20;, score=0.484 total time=   0.2s\n",
      "[CV 5/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 5/10; 2/40] END max_depth=1, n_estimators=20;, score=0.472 total time=   0.2s\n",
      "[CV 6/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 6/10; 2/40] END max_depth=1, n_estimators=20;, score=0.494 total time=   0.2s\n",
      "[CV 7/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 7/10; 2/40] END max_depth=1, n_estimators=20;, score=0.432 total time=   0.2s\n",
      "[CV 8/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 8/10; 2/40] END max_depth=1, n_estimators=20;, score=0.446 total time=   0.2s\n",
      "[CV 9/10; 2/40] START max_depth=1, n_estimators=20..............................\n",
      "[CV 9/10; 2/40] END max_depth=1, n_estimators=20;, score=0.554 total time=   0.2s\n",
      "[CV 10/10; 2/40] START max_depth=1, n_estimators=20.............................\n",
      "[CV 10/10; 2/40] END max_depth=1, n_estimators=20;, score=0.498 total time=   0.2s\n",
      "[CV 1/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 1/10; 3/40] END max_depth=1, n_estimators=30;, score=0.547 total time=   0.3s\n",
      "[CV 2/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 2/10; 3/40] END max_depth=1, n_estimators=30;, score=0.516 total time=   0.3s\n",
      "[CV 3/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 3/10; 3/40] END max_depth=1, n_estimators=30;, score=0.505 total time=   0.3s\n",
      "[CV 4/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 4/10; 3/40] END max_depth=1, n_estimators=30;, score=0.457 total time=   0.3s\n",
      "[CV 5/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 5/10; 3/40] END max_depth=1, n_estimators=30;, score=0.555 total time=   0.3s\n",
      "[CV 6/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 6/10; 3/40] END max_depth=1, n_estimators=30;, score=0.552 total time=   0.3s\n",
      "[CV 7/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 7/10; 3/40] END max_depth=1, n_estimators=30;, score=0.490 total time=   0.3s\n",
      "[CV 8/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 8/10; 3/40] END max_depth=1, n_estimators=30;, score=0.525 total time=   0.3s\n",
      "[CV 9/10; 3/40] START max_depth=1, n_estimators=30..............................\n",
      "[CV 9/10; 3/40] END max_depth=1, n_estimators=30;, score=0.467 total time=   0.3s\n",
      "[CV 10/10; 3/40] START max_depth=1, n_estimators=30.............................\n",
      "[CV 10/10; 3/40] END max_depth=1, n_estimators=30;, score=0.490 total time=   0.3s\n",
      "[CV 1/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 1/10; 4/40] END max_depth=1, n_estimators=40;, score=0.516 total time=   0.3s\n",
      "[CV 2/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 2/10; 4/40] END max_depth=1, n_estimators=40;, score=0.547 total time=   0.3s\n",
      "[CV 3/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 3/10; 4/40] END max_depth=1, n_estimators=40;, score=0.505 total time=   0.3s\n",
      "[CV 4/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 4/10; 4/40] END max_depth=1, n_estimators=40;, score=0.468 total time=   0.3s\n",
      "[CV 5/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 5/10; 4/40] END max_depth=1, n_estimators=40;, score=0.488 total time=   0.3s\n",
      "[CV 6/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 6/10; 4/40] END max_depth=1, n_estimators=40;, score=0.541 total time=   0.3s\n",
      "[CV 7/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 7/10; 4/40] END max_depth=1, n_estimators=40;, score=0.527 total time=   0.3s\n",
      "[CV 8/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 8/10; 4/40] END max_depth=1, n_estimators=40;, score=0.490 total time=   0.3s\n",
      "[CV 9/10; 4/40] START max_depth=1, n_estimators=40..............................\n",
      "[CV 9/10; 4/40] END max_depth=1, n_estimators=40;, score=0.575 total time=   0.3s\n",
      "[CV 10/10; 4/40] START max_depth=1, n_estimators=40.............................\n",
      "[CV 10/10; 4/40] END max_depth=1, n_estimators=40;, score=0.543 total time=   0.3s\n",
      "[CV 1/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 1/10; 5/40] END max_depth=3, n_estimators=10;, score=0.660 total time=   0.2s\n",
      "[CV 2/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 2/10; 5/40] END max_depth=3, n_estimators=10;, score=0.639 total time=   0.2s\n",
      "[CV 3/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 3/10; 5/40] END max_depth=3, n_estimators=10;, score=0.669 total time=   0.2s\n",
      "[CV 4/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 4/10; 5/40] END max_depth=3, n_estimators=10;, score=0.633 total time=   0.2s\n",
      "[CV 5/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 5/10; 5/40] END max_depth=3, n_estimators=10;, score=0.684 total time=   0.2s\n",
      "[CV 6/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 6/10; 5/40] END max_depth=3, n_estimators=10;, score=0.690 total time=   0.2s\n",
      "[CV 7/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 7/10; 5/40] END max_depth=3, n_estimators=10;, score=0.652 total time=   0.2s\n",
      "[CV 8/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 8/10; 5/40] END max_depth=3, n_estimators=10;, score=0.686 total time=   0.2s\n",
      "[CV 9/10; 5/40] START max_depth=3, n_estimators=10..............................\n",
      "[CV 9/10; 5/40] END max_depth=3, n_estimators=10;, score=0.691 total time=   0.2s\n",
      "[CV 10/10; 5/40] START max_depth=3, n_estimators=10.............................\n",
      "[CV 10/10; 5/40] END max_depth=3, n_estimators=10;, score=0.664 total time=   0.2s\n",
      "[CV 1/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 1/10; 6/40] END max_depth=3, n_estimators=20;, score=0.713 total time=   0.4s\n",
      "[CV 2/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 2/10; 6/40] END max_depth=3, n_estimators=20;, score=0.704 total time=   0.4s\n",
      "[CV 3/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 3/10; 6/40] END max_depth=3, n_estimators=20;, score=0.736 total time=   0.4s\n",
      "[CV 4/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 4/10; 6/40] END max_depth=3, n_estimators=20;, score=0.733 total time=   0.4s\n",
      "[CV 5/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 5/10; 6/40] END max_depth=3, n_estimators=20;, score=0.715 total time=   0.4s\n",
      "[CV 6/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 6/10; 6/40] END max_depth=3, n_estimators=20;, score=0.698 total time=   0.4s\n",
      "[CV 7/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 7/10; 6/40] END max_depth=3, n_estimators=20;, score=0.661 total time=   0.4s\n",
      "[CV 8/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 8/10; 6/40] END max_depth=3, n_estimators=20;, score=0.715 total time=   0.4s\n",
      "[CV 9/10; 6/40] START max_depth=3, n_estimators=20..............................\n",
      "[CV 9/10; 6/40] END max_depth=3, n_estimators=20;, score=0.718 total time=   0.4s\n",
      "[CV 10/10; 6/40] START max_depth=3, n_estimators=20.............................\n",
      "[CV 10/10; 6/40] END max_depth=3, n_estimators=20;, score=0.682 total time=   0.4s\n",
      "[CV 1/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 1/10; 7/40] END max_depth=3, n_estimators=30;, score=0.740 total time=   0.6s\n",
      "[CV 2/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 2/10; 7/40] END max_depth=3, n_estimators=30;, score=0.732 total time=   0.6s\n",
      "[CV 3/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 3/10; 7/40] END max_depth=3, n_estimators=30;, score=0.715 total time=   0.5s\n",
      "[CV 4/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 4/10; 7/40] END max_depth=3, n_estimators=30;, score=0.695 total time=   0.6s\n",
      "[CV 5/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 5/10; 7/40] END max_depth=3, n_estimators=30;, score=0.732 total time=   0.6s\n",
      "[CV 6/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 6/10; 7/40] END max_depth=3, n_estimators=30;, score=0.711 total time=   0.6s\n",
      "[CV 7/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 7/10; 7/40] END max_depth=3, n_estimators=30;, score=0.709 total time=   0.6s\n",
      "[CV 8/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 8/10; 7/40] END max_depth=3, n_estimators=30;, score=0.723 total time=   0.6s\n",
      "[CV 9/10; 7/40] START max_depth=3, n_estimators=30..............................\n",
      "[CV 9/10; 7/40] END max_depth=3, n_estimators=30;, score=0.740 total time=   0.6s\n",
      "[CV 10/10; 7/40] START max_depth=3, n_estimators=30.............................\n",
      "[CV 10/10; 7/40] END max_depth=3, n_estimators=30;, score=0.731 total time=   0.6s\n",
      "[CV 1/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 1/10; 8/40] END max_depth=3, n_estimators=40;, score=0.732 total time=   0.7s\n",
      "[CV 2/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 2/10; 8/40] END max_depth=3, n_estimators=40;, score=0.713 total time=   0.7s\n",
      "[CV 3/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 3/10; 8/40] END max_depth=3, n_estimators=40;, score=0.741 total time=   0.7s\n",
      "[CV 4/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 4/10; 8/40] END max_depth=3, n_estimators=40;, score=0.728 total time=   0.7s\n",
      "[CV 5/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 5/10; 8/40] END max_depth=3, n_estimators=40;, score=0.751 total time=   0.7s\n",
      "[CV 6/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 6/10; 8/40] END max_depth=3, n_estimators=40;, score=0.723 total time=   0.7s\n",
      "[CV 7/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 7/10; 8/40] END max_depth=3, n_estimators=40;, score=0.721 total time=   0.7s\n",
      "[CV 8/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 8/10; 8/40] END max_depth=3, n_estimators=40;, score=0.722 total time=   0.7s\n",
      "[CV 9/10; 8/40] START max_depth=3, n_estimators=40..............................\n",
      "[CV 9/10; 8/40] END max_depth=3, n_estimators=40;, score=0.740 total time=   0.8s\n",
      "[CV 10/10; 8/40] START max_depth=3, n_estimators=40.............................\n",
      "[CV 10/10; 8/40] END max_depth=3, n_estimators=40;, score=0.726 total time=   0.8s\n",
      "[CV 1/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 1/10; 9/40] END max_depth=5, n_estimators=10;, score=0.810 total time=   0.3s\n",
      "[CV 2/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 2/10; 9/40] END max_depth=5, n_estimators=10;, score=0.790 total time=   0.3s\n",
      "[CV 3/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 3/10; 9/40] END max_depth=5, n_estimators=10;, score=0.816 total time=   0.4s\n",
      "[CV 4/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 4/10; 9/40] END max_depth=5, n_estimators=10;, score=0.799 total time=   0.3s\n",
      "[CV 5/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 5/10; 9/40] END max_depth=5, n_estimators=10;, score=0.791 total time=   0.3s\n",
      "[CV 6/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 6/10; 9/40] END max_depth=5, n_estimators=10;, score=0.803 total time=   0.4s\n",
      "[CV 7/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 7/10; 9/40] END max_depth=5, n_estimators=10;, score=0.784 total time=   0.3s\n",
      "[CV 8/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 8/10; 9/40] END max_depth=5, n_estimators=10;, score=0.801 total time=   0.4s\n",
      "[CV 9/10; 9/40] START max_depth=5, n_estimators=10..............................\n",
      "[CV 9/10; 9/40] END max_depth=5, n_estimators=10;, score=0.830 total time=   0.4s\n",
      "[CV 10/10; 9/40] START max_depth=5, n_estimators=10.............................\n",
      "[CV 10/10; 9/40] END max_depth=5, n_estimators=10;, score=0.816 total time=   0.4s\n",
      "[CV 1/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 1/10; 10/40] END max_depth=5, n_estimators=20;, score=0.850 total time=   0.6s\n",
      "[CV 2/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 2/10; 10/40] END max_depth=5, n_estimators=20;, score=0.826 total time=   0.6s\n",
      "[CV 3/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 3/10; 10/40] END max_depth=5, n_estimators=20;, score=0.834 total time=   0.7s\n",
      "[CV 4/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 4/10; 10/40] END max_depth=5, n_estimators=20;, score=0.828 total time=   0.7s\n",
      "[CV 5/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 5/10; 10/40] END max_depth=5, n_estimators=20;, score=0.838 total time=   0.7s\n",
      "[CV 6/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 6/10; 10/40] END max_depth=5, n_estimators=20;, score=0.838 total time=   0.6s\n",
      "[CV 7/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 7/10; 10/40] END max_depth=5, n_estimators=20;, score=0.822 total time=   0.6s\n",
      "[CV 8/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 8/10; 10/40] END max_depth=5, n_estimators=20;, score=0.822 total time=   0.6s\n",
      "[CV 9/10; 10/40] START max_depth=5, n_estimators=20.............................\n",
      "[CV 9/10; 10/40] END max_depth=5, n_estimators=20;, score=0.849 total time=   0.6s\n",
      "[CV 10/10; 10/40] START max_depth=5, n_estimators=20............................\n",
      "[CV 10/10; 10/40] END max_depth=5, n_estimators=20;, score=0.828 total time=   0.6s\n",
      "[CV 1/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 1/10; 11/40] END max_depth=5, n_estimators=30;, score=0.852 total time=   0.9s\n",
      "[CV 2/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 2/10; 11/40] END max_depth=5, n_estimators=30;, score=0.846 total time=   1.0s\n",
      "[CV 3/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 3/10; 11/40] END max_depth=5, n_estimators=30;, score=0.830 total time=   1.0s\n",
      "[CV 4/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 4/10; 11/40] END max_depth=5, n_estimators=30;, score=0.836 total time=   0.9s\n",
      "[CV 5/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 5/10; 11/40] END max_depth=5, n_estimators=30;, score=0.843 total time=   0.9s\n",
      "[CV 6/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 6/10; 11/40] END max_depth=5, n_estimators=30;, score=0.841 total time=   0.9s\n",
      "[CV 7/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 7/10; 11/40] END max_depth=5, n_estimators=30;, score=0.839 total time=   0.9s\n",
      "[CV 8/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 8/10; 11/40] END max_depth=5, n_estimators=30;, score=0.844 total time=   0.9s\n",
      "[CV 9/10; 11/40] START max_depth=5, n_estimators=30.............................\n",
      "[CV 9/10; 11/40] END max_depth=5, n_estimators=30;, score=0.858 total time=   0.9s\n",
      "[CV 10/10; 11/40] START max_depth=5, n_estimators=30............................\n",
      "[CV 10/10; 11/40] END max_depth=5, n_estimators=30;, score=0.856 total time=   0.9s\n",
      "[CV 1/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 1/10; 12/40] END max_depth=5, n_estimators=40;, score=0.859 total time=   1.2s\n",
      "[CV 2/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 2/10; 12/40] END max_depth=5, n_estimators=40;, score=0.853 total time=   1.2s\n",
      "[CV 3/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 3/10; 12/40] END max_depth=5, n_estimators=40;, score=0.847 total time=   1.2s\n",
      "[CV 4/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 4/10; 12/40] END max_depth=5, n_estimators=40;, score=0.841 total time=   1.2s\n",
      "[CV 5/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 5/10; 12/40] END max_depth=5, n_estimators=40;, score=0.835 total time=   1.2s\n",
      "[CV 6/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 6/10; 12/40] END max_depth=5, n_estimators=40;, score=0.851 total time=   1.2s\n",
      "[CV 7/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 7/10; 12/40] END max_depth=5, n_estimators=40;, score=0.835 total time=   1.2s\n",
      "[CV 8/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 8/10; 12/40] END max_depth=5, n_estimators=40;, score=0.837 total time=   1.2s\n",
      "[CV 9/10; 12/40] START max_depth=5, n_estimators=40.............................\n",
      "[CV 9/10; 12/40] END max_depth=5, n_estimators=40;, score=0.863 total time=   1.2s\n",
      "[CV 10/10; 12/40] START max_depth=5, n_estimators=40............................\n",
      "[CV 10/10; 12/40] END max_depth=5, n_estimators=40;, score=0.855 total time=   1.2s\n",
      "[CV 1/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 1/10; 13/40] END max_depth=7, n_estimators=10;, score=0.871 total time=   0.5s\n",
      "[CV 2/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 2/10; 13/40] END max_depth=7, n_estimators=10;, score=0.865 total time=   0.5s\n",
      "[CV 3/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 3/10; 13/40] END max_depth=7, n_estimators=10;, score=0.876 total time=   0.5s\n",
      "[CV 4/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 4/10; 13/40] END max_depth=7, n_estimators=10;, score=0.870 total time=   0.5s\n",
      "[CV 5/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 5/10; 13/40] END max_depth=7, n_estimators=10;, score=0.866 total time=   0.5s\n",
      "[CV 6/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 6/10; 13/40] END max_depth=7, n_estimators=10;, score=0.878 total time=   0.5s\n",
      "[CV 7/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 7/10; 13/40] END max_depth=7, n_estimators=10;, score=0.870 total time=   0.5s\n",
      "[CV 8/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 8/10; 13/40] END max_depth=7, n_estimators=10;, score=0.876 total time=   0.5s\n",
      "[CV 9/10; 13/40] START max_depth=7, n_estimators=10.............................\n",
      "[CV 9/10; 13/40] END max_depth=7, n_estimators=10;, score=0.885 total time=   0.5s\n",
      "[CV 10/10; 13/40] START max_depth=7, n_estimators=10............................\n",
      "[CV 10/10; 13/40] END max_depth=7, n_estimators=10;, score=0.872 total time=   0.5s\n",
      "[CV 1/10; 14/40] START max_depth=7, n_estimators=20.............................\n",
      "[CV 1/10; 14/40] END max_depth=7, n_estimators=20;, score=0.899 total time=   0.9s\n",
      "[CV 2/10; 14/40] START max_depth=7, n_estimators=20.............................\n",
      "[CV 2/10; 14/40] END max_depth=7, n_estimators=20;, score=0.892 total time=   0.9s\n",
      "[CV 3/10; 14/40] START max_depth=7, n_estimators=20.............................\n",
      "[CV 3/10; 14/40] END max_depth=7, n_estimators=20;, score=0.889 total time=   0.9s\n",
      "[CV 4/10; 14/40] START max_depth=7, n_estimators=20.............................\n",
      "[CV 4/10; 14/40] END max_depth=7, n_estimators=20;, score=0.896 total time=   0.9s\n",
      "[CV 5/10; 14/40] START max_depth=7, n_estimators=20.............................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m:[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m2\u001b[39m)], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m:[i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m10\u001b[39m)]}\n\u001b[1;32m      5\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(clf, parameters,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(clf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:890\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    888\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf = RandomForestClassifier()\n",
    "parameters = {'max_depth':[i for i in range(1,20,2)], 'n_estimators':[i for i in range(10,50,10)]}\n",
    "clf = GridSearchCV(clf, parameters,cv=10, scoring='accuracy', verbose=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577114427860696\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 6, 2, ..., 8, 3, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision score (micro) = 0.9559884559884559\n",
      "precision score (macro) = 0.9556420502196328\n",
      "precision score (weighted) = 0.9559496697827149\n"
     ]
    }
   ],
   "source": [
    "#evaluate model\n",
    "from sklearn.metrics import precision_score\n",
    "print(f\"precision score (micro) = {precision_score(y_test, y_pred, average='micro')}\")\n",
    "print(f\"precision score (macro) = {precision_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"precision score (weighted) = {precision_score(y_test, y_pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score <br>\n",
    "precision score (micro) = 0.9559884559884559 <br>\n",
    "precision score (macro) = 0.9556420502196328 <br>\n",
    "precision score (weighted) = 0.9559496697827149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network (pyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to dataloader\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#1/4 to val sey\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=55)\n",
    "\n",
    "torch_X_train = torch.FloatTensor(X_train.values).to(device)\n",
    "torch_y_train = torch.LongTensor(y_train.values).to(device)\n",
    "\n",
    "torch_X_val = torch.FloatTensor(X_val.values).to(device)\n",
    "torch_y_val = torch.LongTensor(y_val.values).to(device)\n",
    "\n",
    "torch_X_test = torch.FloatTensor(X_test.values).to(device)\n",
    "torch_y_test = torch.LongTensor(y_test.values).to(device)\n",
    "\n",
    "ds_X_train = TensorDataset(torch_X_train, torch_y_train)\n",
    "ds_X_test = TensorDataset(torch_X_test, torch_y_test)\n",
    "ds_X_val = TensorDataset(torch_X_val, torch_y_val)\n",
    "\n",
    "train_loader = DataLoader(ds_X_train, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(ds_X_test, batch_size=10, shuffle=False)\n",
    "val_loader = DataLoader(ds_X_val, batch_size=10, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute mean loss of the model from the validation set\n",
    "def compute_val_loss(model, v_loader, criterion):\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in v_loader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss/len(v_loader)\n",
    "\n",
    "def train_model(model,train_loader,criterion,optimizer,epochs=3):\n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            #forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            #backward and optimise\n",
    "            loss.backward() #compute gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if i%20 == 19:\n",
    "                loss_history.append(running_loss/100)\n",
    "                val_loss_history.append(compute_val_loss(model, val_loader, criterion))\n",
    "\n",
    "                print('[epoch => %d,%5d] loss: %.3f' % (epoch+1, i+1, running_loss/100))\n",
    "                running_loss = 0.0\n",
    "    return loss_history ,val_loss_history\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch => 1,   20] loss: 0.496\n",
      "[epoch => 1,   40] loss: 0.315\n",
      "[epoch => 1,   60] loss: 0.195\n",
      "[epoch => 1,   80] loss: 0.200\n",
      "[epoch => 1,  100] loss: 0.144\n",
      "[epoch => 1,  120] loss: 0.146\n",
      "[epoch => 1,  140] loss: 0.157\n",
      "[epoch => 1,  160] loss: 0.123\n",
      "[epoch => 1,  180] loss: 0.145\n",
      "[epoch => 1,  200] loss: 0.094\n",
      "[epoch => 1,  220] loss: 0.106\n",
      "[epoch => 1,  240] loss: 0.077\n",
      "[epoch => 1,  260] loss: 0.134\n",
      "[epoch => 1,  280] loss: 0.119\n",
      "[epoch => 1,  300] loss: 0.100\n",
      "[epoch => 1,  320] loss: 0.078\n",
      "[epoch => 1,  340] loss: 0.082\n",
      "[epoch => 1,  360] loss: 0.090\n",
      "[epoch => 1,  380] loss: 0.081\n",
      "[epoch => 1,  400] loss: 0.084\n",
      "[epoch => 1,  420] loss: 0.078\n",
      "[epoch => 1,  440] loss: 0.091\n",
      "[epoch => 1,  460] loss: 0.077\n",
      "[epoch => 1,  480] loss: 0.082\n",
      "[epoch => 1,  500] loss: 0.064\n",
      "[epoch => 1,  520] loss: 0.085\n",
      "[epoch => 1,  540] loss: 0.088\n",
      "[epoch => 1,  560] loss: 0.088\n",
      "[epoch => 1,  580] loss: 0.077\n",
      "[epoch => 1,  600] loss: 0.082\n",
      "[epoch => 1,  620] loss: 0.081\n",
      "[epoch => 1,  640] loss: 0.061\n",
      "[epoch => 1,  660] loss: 0.058\n",
      "[epoch => 1,  680] loss: 0.069\n",
      "[epoch => 1,  700] loss: 0.075\n",
      "[epoch => 1,  720] loss: 0.049\n",
      "[epoch => 1,  740] loss: 0.061\n",
      "[epoch => 1,  760] loss: 0.062\n",
      "[epoch => 1,  780] loss: 0.063\n",
      "[epoch => 1,  800] loss: 0.070\n",
      "[epoch => 1,  820] loss: 0.092\n",
      "[epoch => 1,  840] loss: 0.069\n",
      "[epoch => 1,  860] loss: 0.082\n",
      "[epoch => 1,  880] loss: 0.053\n",
      "[epoch => 1,  900] loss: 0.071\n",
      "[epoch => 1,  920] loss: 0.078\n",
      "[epoch => 1,  940] loss: 0.033\n",
      "[epoch => 1,  960] loss: 0.059\n",
      "[epoch => 1,  980] loss: 0.068\n",
      "[epoch => 1, 1000] loss: 0.062\n",
      "[epoch => 1, 1020] loss: 0.076\n",
      "[epoch => 1, 1040] loss: 0.048\n",
      "[epoch => 1, 1060] loss: 0.068\n",
      "[epoch => 1, 1080] loss: 0.061\n",
      "[epoch => 1, 1100] loss: 0.066\n",
      "[epoch => 1, 1120] loss: 0.067\n",
      "[epoch => 1, 1140] loss: 0.076\n",
      "[epoch => 1, 1160] loss: 0.064\n",
      "[epoch => 1, 1180] loss: 0.055\n",
      "[epoch => 1, 1200] loss: 0.062\n",
      "[epoch => 1, 1220] loss: 0.037\n",
      "[epoch => 1, 1240] loss: 0.053\n",
      "[epoch => 1, 1260] loss: 0.041\n",
      "[epoch => 1, 1280] loss: 0.042\n",
      "[epoch => 1, 1300] loss: 0.054\n",
      "[epoch => 1, 1320] loss: 0.057\n",
      "[epoch => 1, 1340] loss: 0.032\n",
      "[epoch => 1, 1360] loss: 0.044\n",
      "[epoch => 1, 1380] loss: 0.058\n",
      "[epoch => 1, 1400] loss: 0.052\n",
      "[epoch => 1, 1420] loss: 0.042\n",
      "[epoch => 1, 1440] loss: 0.040\n",
      "[epoch => 1, 1460] loss: 0.048\n",
      "[epoch => 1, 1480] loss: 0.042\n",
      "[epoch => 1, 1500] loss: 0.037\n",
      "[epoch => 1, 1520] loss: 0.048\n",
      "[epoch => 1, 1540] loss: 0.094\n",
      "[epoch => 1, 1560] loss: 0.093\n",
      "[epoch => 1, 1580] loss: 0.051\n",
      "[epoch => 1, 1600] loss: 0.059\n",
      "[epoch => 1, 1620] loss: 0.057\n",
      "[epoch => 1, 1640] loss: 0.060\n",
      "[epoch => 1, 1660] loss: 0.046\n",
      "[epoch => 1, 1680] loss: 0.058\n",
      "[epoch => 1, 1700] loss: 0.040\n",
      "[epoch => 1, 1720] loss: 0.069\n",
      "[epoch => 1, 1740] loss: 0.033\n",
      "[epoch => 1, 1760] loss: 0.036\n",
      "[epoch => 1, 1780] loss: 0.040\n",
      "[epoch => 1, 1800] loss: 0.030\n",
      "[epoch => 1, 1820] loss: 0.046\n",
      "[epoch => 1, 1840] loss: 0.049\n",
      "[epoch => 1, 1860] loss: 0.060\n",
      "[epoch => 1, 1880] loss: 0.031\n",
      "[epoch => 1, 1900] loss: 0.050\n",
      "[epoch => 1, 1920] loss: 0.054\n",
      "[epoch => 1, 1940] loss: 0.042\n",
      "[epoch => 1, 1960] loss: 0.027\n",
      "[epoch => 1, 1980] loss: 0.052\n",
      "[epoch => 1, 2000] loss: 0.040\n",
      "[epoch => 1, 2020] loss: 0.050\n",
      "[epoch => 1, 2040] loss: 0.056\n",
      "[epoch => 1, 2060] loss: 0.044\n",
      "[epoch => 1, 2080] loss: 0.040\n",
      "[epoch => 1, 2100] loss: 0.047\n",
      "[epoch => 2,   20] loss: 0.047\n",
      "[epoch => 2,   40] loss: 0.043\n",
      "[epoch => 2,   60] loss: 0.028\n",
      "[epoch => 2,   80] loss: 0.033\n",
      "[epoch => 2,  100] loss: 0.047\n",
      "[epoch => 2,  120] loss: 0.031\n",
      "[epoch => 2,  140] loss: 0.043\n",
      "[epoch => 2,  160] loss: 0.019\n",
      "[epoch => 2,  180] loss: 0.018\n",
      "[epoch => 2,  200] loss: 0.035\n",
      "[epoch => 2,  220] loss: 0.028\n",
      "[epoch => 2,  240] loss: 0.026\n",
      "[epoch => 2,  260] loss: 0.037\n",
      "[epoch => 2,  280] loss: 0.023\n",
      "[epoch => 2,  300] loss: 0.020\n",
      "[epoch => 2,  320] loss: 0.028\n",
      "[epoch => 2,  340] loss: 0.027\n",
      "[epoch => 2,  360] loss: 0.031\n",
      "[epoch => 2,  380] loss: 0.023\n",
      "[epoch => 2,  400] loss: 0.035\n",
      "[epoch => 2,  420] loss: 0.036\n",
      "[epoch => 2,  440] loss: 0.031\n",
      "[epoch => 2,  460] loss: 0.042\n",
      "[epoch => 2,  480] loss: 0.023\n",
      "[epoch => 2,  500] loss: 0.018\n",
      "[epoch => 2,  520] loss: 0.033\n",
      "[epoch => 2,  540] loss: 0.038\n",
      "[epoch => 2,  560] loss: 0.023\n",
      "[epoch => 2,  580] loss: 0.050\n",
      "[epoch => 2,  600] loss: 0.042\n",
      "[epoch => 2,  620] loss: 0.029\n",
      "[epoch => 2,  640] loss: 0.051\n",
      "[epoch => 2,  660] loss: 0.033\n",
      "[epoch => 2,  680] loss: 0.030\n",
      "[epoch => 2,  700] loss: 0.025\n",
      "[epoch => 2,  720] loss: 0.022\n",
      "[epoch => 2,  740] loss: 0.022\n",
      "[epoch => 2,  760] loss: 0.049\n",
      "[epoch => 2,  780] loss: 0.016\n",
      "[epoch => 2,  800] loss: 0.029\n",
      "[epoch => 2,  820] loss: 0.042\n",
      "[epoch => 2,  840] loss: 0.018\n",
      "[epoch => 2,  860] loss: 0.015\n",
      "[epoch => 2,  880] loss: 0.021\n",
      "[epoch => 2,  900] loss: 0.024\n",
      "[epoch => 2,  920] loss: 0.032\n",
      "[epoch => 2,  940] loss: 0.031\n",
      "[epoch => 2,  960] loss: 0.021\n",
      "[epoch => 2,  980] loss: 0.053\n",
      "[epoch => 2, 1000] loss: 0.029\n",
      "[epoch => 2, 1020] loss: 0.024\n",
      "[epoch => 2, 1040] loss: 0.045\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_his,val_loss_his = train_model(model, train_loader, criterion, optimizer, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_his)\n",
    "plt.plot(val_loss_his)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, test):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        n_correct = 0\n",
    "        n_total = 0\n",
    "        for batch_X, batch_y in test:\n",
    "            outputs = model(batch_X) # batch size x 3\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            n_total += batch_y.size(0)\n",
    "            n_correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_total\n",
    "        print(f'Accuracy of the network on the {len(test)} test samples: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1386 test samples: 96.1976911976912 %\n"
     ]
    }
   ],
   "source": [
    "accuracy(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
